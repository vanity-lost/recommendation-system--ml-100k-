{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms import NormalPredictor\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD, NMF\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, KFold as KFold_sp\n",
    "from surprise.model_selection.split import train_test_split as tts_sp\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Embedding, Flatten, Dropout, Dense, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "from keras import callbacks\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae\n",
    "from sklearn.model_selection import cross_validate as cv_sk, KFold as KFold_sk, train_test_split as tts_sk\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "roberta = SentenceTransformer('stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv('ratings.csv')\n",
    "ratings_df = ratings_df.drop(ratings_df.columns[-1], axis=1)\n",
    "\n",
    "tags = pd.read_csv('tags.csv')\n",
    "tags = tags.drop(tags.columns[-1], axis=1)\n",
    "\n",
    "ratings = Dataset.load_from_df(ratings_df, Reader(rating_scale=(1, 5)))\n",
    "kf_sp = KFold_sp(n_splits=5, shuffle=False)\n",
    "\n",
    "ratings_mat = ratings_df.to_numpy()\n",
    "kf_sk = KFold_sk(n_splits=5, shuffle=False)\n",
    "\n",
    "vecs = np.load('encodedText.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame()\n",
    "user_enc = LabelEncoder()\n",
    "temp_df['user'] = user_enc.fit_transform(ratings_df['userId'].values)\n",
    "item_enc = LabelEncoder()\n",
    "temp_df['movie'] = item_enc.fit_transform(ratings_df['movieId'].values)\n",
    "temp_df['rating'] = ratings_df['rating'].values.astype(np.float32)\n",
    "\n",
    "n_users = temp_df['user'].nunique()\n",
    "n_movies = temp_df['movie'].nunique()\n",
    "min_rating = min(temp_df['rating'])\n",
    "max_rating = max(temp_df['rating'])\n",
    "\n",
    "temp = temp_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Performance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results of algorithm random, NMF, and SVD\n",
    "algo_1 = cross_validate(NormalPredictor(), ratings, cv=kf_sp, n_jobs=-1, measures=['rmse', 'mae'])\n",
    "algo_2 = cross_validate(NMF(n_factors=17, n_epochs=30, random_state=12345), ratings, cv=kf_sp, n_jobs=-1, measures=['rmse', 'mae'])\n",
    "algo_3 = cross_validate(SVD(n_factors=7, n_epochs=550, random_state=12345), ratings, cv=kf_sp, n_jobs=-1, measures=['rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions from knn\n",
    "algo_4 = {'test_rmse': [], 'test_mae': [], 'test_time': []}\n",
    "\n",
    "for train_index, test_index in kf_sk.split(ratings_mat):\n",
    "    knn = KNN(n_neighbors=6, n_jobs=-1)\n",
    "    X_train, X_test = vecs[train_index], vecs[test_index]\n",
    "    y_train, y_test = ratings_mat[train_index, -1], ratings_mat[test_index, -1]\n",
    "    knn.fit(X_train, y_train)\n",
    "    start_time = time.time()\n",
    "    preds = knn.predict(X_test)\n",
    "    algo_4['test_time'].append(round(time.time() - start_time, 10))\n",
    "    algo_4['test_rmse'].append(mse(y_test, preds, squared=False))\n",
    "    algo_4['test_mae'].append(mae(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    user = Input(shape=(1,))\n",
    "    u = Embedding(n_users, 32, embeddings_initializer='he_normal',\n",
    "                      embeddings_regularizer=l2(1e-6))(user)\n",
    "    u = Flatten()(u)\n",
    "\n",
    "    movie = Input(shape=(1,))\n",
    "    m = Embedding(n_movies, 32, embeddings_initializer='he_normal',\n",
    "                      embeddings_regularizer=l2(1e-6))(movie)\n",
    "    m = Flatten()(m)\n",
    "\n",
    "    x = Concatenate()([u, m])\n",
    "\n",
    "    x = Dense(16, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "\n",
    "    model = Model([user, movie], x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "earlystop = callbacks.EarlyStopping(patience=3,\n",
    "                                    monitor='val_loss',\n",
    "                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results of algorithm neural network\n",
    "algo_5 = {'test_rmse': [], 'test_mae': [], 'test_time': []}\n",
    "\n",
    "for train_index, test_index in kf_sk.split(temp):\n",
    "    train, test = temp[train_index], temp[test_index]\n",
    "    model = build_model()\n",
    "    history = model.fit([train[:, 0], train[:, 1]], train[:, 2], epochs=10, verbose=0, callbacks=[earlystop], batch_size=64, validation_split=0.1)\n",
    "    start_time = time.time()\n",
    "    preds = model.predict([test[:, 0], test[:, 1]])\n",
    "    algo_5['test_time'].append(round(time.time() - start_time, 10))\n",
    "    algo_5['test_rmse'].append(mse(test[:, 2], preds, squared=False))\n",
    "    algo_5['test_mae'].append(mae(test[:, 2], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4263\t 1.1387\t 0.1021\t\n",
      "1.0429\t 0.8296\t 0.0902\t\n",
      "0.9640\t 0.7480\t 0.0746\t\n",
      "1.4478\t 1.2488\t 35.6309\t\n",
      "0.9627\t 0.7525\t 0.6441\t\n"
     ]
    }
   ],
   "source": [
    "for i in [algo_1, algo_2, algo_3, algo_4, algo_5]:\n",
    "    print(f\"{np.mean(i['test_rmse']):.4f}\\t {np.mean(i['test_mae']):.4f}\\t {np.mean(i['test_time']):.4f}\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        RMSE     MAE     Time\n",
    "random  1.4263\t 1.1387\t 0.1021\t\n",
    "NMF     1.0429\t 0.8296\t 0.0902\t\n",
    "SVD     0.9640\t 0.7480\t 0.0746\t\n",
    "KNN     1.4478\t 1.2488\t 35.6309\t\n",
    "nn      0.9627\t 0.7525\t 0.6441\t\n",
    "\n",
    "* nn: neural network\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Consistency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from all 5 algorithms\n",
    "preds = []\n",
    "\n",
    "# predictions from random, nmf, svd\n",
    "trainset, testset = tts_sp(ratings, test_size=.25, shuffle=False)\n",
    "preds.append([i.est for i in NormalPredictor().fit(trainset).test(testset)])\n",
    "preds.append([i.est for i in NMF(n_factors=17, n_epochs=30, random_state=12345).fit(trainset).test(testset)])\n",
    "preds.append([i.est for i in SVD(n_factors=7, n_epochs=550, random_state=12345).fit(trainset).test(testset)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions from knn\n",
    "X_train, X_test = tts_sk(vecs, test_size=.25, shuffle=False)\n",
    "train_data, test_data = tts_sk(ratings_mat, test_size=.25, shuffle=False)\n",
    "knn = KNN(n_neighbors=6, n_jobs=-1)\n",
    "preds.append(knn.fit(X_train, train_data[:, -1]).predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions from neural network\n",
    "train_data, test_data = tts_sk(temp, test_size=.25, shuffle=False)\n",
    "model = build_model()\n",
    "history = model.fit([train_data[:, 0], train_data[:, 1]], train_data[:, 2], epochs=10, verbose=0, callbacks=[earlystop], batch_size=64, validation_split=0.1)\n",
    "preds.append(model.predict([test_data[:, 0], test_data[:, 1]]).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00\t0.96\t1.06\t0.97\t1.05\t\n",
      "0.96\t0.00\t0.44\t0.12\t0.43\t\n",
      "1.06\t0.44\t0.00\t0.45\t0.23\t\n",
      "0.97\t0.12\t0.45\t0.00\t0.44\t\n",
      "1.05\t0.43\t0.23\t0.44\t0.00\t\n"
     ]
    }
   ],
   "source": [
    "for i in preds:\n",
    "    res = []\n",
    "    for j in preds:\n",
    "        res.append(mse(i, j, squared=False))\n",
    "    s = ''.join(f\"{np.mean(r):.2f}\\t\" for r in res)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        random  NMF     SVD     KNN     nn\n",
    "random  0.00\t0.96\t1.06\t0.97\t1.05\t\n",
    "NMF     0.96\t0.00\t0.44\t0.12\t0.43\t\n",
    "SVD     1.06\t0.44\t0.00\t0.45\t0.23\t\n",
    "KNN     0.97\t0.12\t0.45\t0.00\t0.44\t\n",
    "nn      1.05\t0.43\t0.23\t0.44\t0.00\t\n",
    "\n",
    "* nn: neural network\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
